{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install TextBlob\n",
    "pip install python-rake\n",
    "conda install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim import corpora, models, similarities\n",
    "import textblob as tb\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk.stem import *\n",
    "import urllib2\n",
    "from gensim import corpora, models, similarities\n",
    "import slugify as sl\n",
    "import pickle\n",
    "import re\n",
    "import RAKE\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, clean and filter our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropbox = \"/Users/mr/Dropbox/moviemeta/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movieplots = pd.read_csv(dropbox + 'movieplots.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean(row):\n",
    "    '''apply on rows of a dataframe to clean up'''\n",
    "    #this is because CSV conversion has converted list into string\n",
    "    row['plots'] = literal_eval(row['plots'])\n",
    "    try:\n",
    "        row['year'] = int(row['year'])\n",
    "        return row\n",
    "    except:\n",
    "        row['year'] = np.nan\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movieplots = movieplots.apply(clean, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftouse = movieplots[movieplots.year > 2014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259028, 5)\n",
      "(16943, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "      <th>year</th>\n",
       "      <th>plots</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#1 at the Apocalypse Box Office (2015)</td>\n",
       "      <td>imdb</td>\n",
       "      <td>2015</td>\n",
       "      <td>[Jules is, self declared, the most useless per...</td>\n",
       "      <td>user plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#50Fathers (2015)</td>\n",
       "      <td>imdb</td>\n",
       "      <td>2015</td>\n",
       "      <td>[#50Fathers is an American Dramatic Comedy. Do...</td>\n",
       "      <td>user plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>#BeRobin the Movie (2015)</td>\n",
       "      <td>imdb</td>\n",
       "      <td>2015</td>\n",
       "      <td>[A documentary about Margaret Cho's homeless o...</td>\n",
       "      <td>user plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>#Beings (2015)</td>\n",
       "      <td>imdb</td>\n",
       "      <td>2015</td>\n",
       "      <td>[Beings is the second feature film of Stefanes...</td>\n",
       "      <td>user plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>#Disneyland60 (2015)</td>\n",
       "      <td>imdb</td>\n",
       "      <td>2015</td>\n",
       "      <td>[Kate, a 15 year old college student documents...</td>\n",
       "      <td>user plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     title source  year  \\\n",
       "2   #1 at the Apocalypse Box Office (2015)   imdb  2015   \n",
       "9                        #50Fathers (2015)   imdb  2015   \n",
       "15               #BeRobin the Movie (2015)   imdb  2015   \n",
       "16                          #Beings (2015)   imdb  2015   \n",
       "20                    #Disneyland60 (2015)   imdb  2015   \n",
       "\n",
       "                                                plots       type  \n",
       "2   [Jules is, self declared, the most useless per...  user plot  \n",
       "9   [#50Fathers is an American Dramatic Comedy. Do...  user plot  \n",
       "15  [A documentary about Margaret Cho's homeless o...  user plot  \n",
       "16  [Beings is the second feature film of Stefanes...  user plot  \n",
       "20  [Kate, a 15 year old college student documents...  user plot  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print movieplots.shape\n",
    "print dftouse.shape\n",
    "dftouse.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the movie plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define some functions that we are going to use to process the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slugify (text):\n",
    "    \"\"\"replace special characters with ascii, see https://github.com/un33k/python-slugify\"\"\"\n",
    "    return sl.slugify(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    \"\"\"stem a word with Porter Stemmer\"\"\"\n",
    "    return PorterStemmer().stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num = re.compile('\\d')\n",
    "def contains_number(word):\n",
    "    \"\"\"check if a word contains a number\"\"\"\n",
    "    return bool(num.search(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Rake = RAKE.Rake('/Users/mr/Devel/Harvard/CS109/Project/moviemeta/data/stoplists/FoxStoplist.txt')\n",
    "def keywords(text):\n",
    "    \"\"\"extract keywords from text using RAKE algorithm\"\"\"\n",
    "    keywords = Rake.run(text)\n",
    "    return ' '.join([tup[0] for tup in keywords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentences(text):\n",
    "    \"\"\" tokenize text into sentences using nltk's punkt tokenizer\"\"\"\n",
    "    blob = tb.TextBlob(text.decode('unicode-escape', 'ignore'))\n",
    "    return blob.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process(sents, movie_id=None, stop=False, postags=None ):\n",
    "    \"\"\"process a list of sentences\n",
    "    \n",
    "    Apply stemming, removal of numbers, slugifying to text\n",
    "    Optionally remove stop words, only include words with a certain POS tag\n",
    "    \n",
    "    Args:\n",
    "        sents (list): sentences\n",
    "        movie_id (int): movie id of the document that is processed\n",
    "        stop (bool): remove stopwords\n",
    "        postags(list): list of POS tags\n",
    "    Returns:\n",
    "        tuple containing two represantions of a daocument:\n",
    "        A list of tagged sentences (e.g. for doc2vec) and a list of words (e.g. for topic detection)\n",
    "    \"\"\"\n",
    "    if stop:\n",
    "        stopwords = set(sw.words('english'))\n",
    "    doc_sents  = []\n",
    "    doc_words  = []\n",
    "    for sent in sents:\n",
    "        if postags:\n",
    "            words = sent.tags\n",
    "        else:\n",
    "            words = sent.words\n",
    "        words_processed = []\n",
    "        for word in words:\n",
    "            if postags:\n",
    "                if word[1] not in postags:\n",
    "                    continue\n",
    "                else:\n",
    "                    word = word[0]\n",
    "            if stop and word in stopwords:\n",
    "                    continue\n",
    "            if contains_number(word):\n",
    "                    continue\n",
    "            word = stem(slugify(word))\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            words_processed.append(word)\n",
    "        doc_sents.append(models.doc2vec.LabeledSentence(words_processed,[movie_id]))\n",
    "        doc_words += words_processed \n",
    "    return (doc_sents, doc_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the actual processing. For topic detection we apply keyword extraction, as we want to use only use those words that carry meaning. We then apply normalization and transform the plots into lists of words, that will later be transformed into bags of words for topic detection.\n",
    "For doc2vec we return lists of tagged sentences, as this is the input for a doc2vec training corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_td(row):\n",
    "    \"\"\"process a row of dataframe for topic detection\"\"\"\n",
    "    return process(sentences(keywords(' '.join(row))))[1]\n",
    "documents_tm = dftouse['plots'].apply(process_td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_d2v(row):\n",
    "    movie = row[0]\n",
    "    plots = ' '.join(row[1])\n",
    "    return  process(sentences(plots), movie_id=movie, stop=True)[0]\n",
    "documents_d2v = dftouse[['title','plots']].apply(process_d2v, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jules is, self declared, the most useless person in the post apocalyptic world, until he finds an old film camera and determines to make the greatest movie in the new world... the only movie in the new world. But his first day filming is proving to be much more difficult than he imagined. Who knew that making a movie after the end of the world would be so hard?']\n",
      "\n",
      "[u'post', u'apocalypt', u'world', u'day', u'film', u'film', u'camera', u'useless', u'person', u'self', u'declar', u'world', u'determin', u'movi', u'prove', u'jule', u'imagin', u'hard', u'difficult']\n",
      "\n",
      "[TaggedDocument(words=[u'jule', u'self', u'declar', u'useless', u'person', u'post', u'apocalypt', u'world', u'find', u'old', u'film', u'camera', u'determin', u'make', u'greatest', u'movi', u'new', u'world', u'movi', u'new', u'world'], tags=['#1 at the Apocalypse Box Office (2015)']), TaggedDocument(words=[u'but', u'first', u'day', u'film', u'prove', u'much', u'difficult', u'imagin'], tags=['#1 at the Apocalypse Box Office (2015)']), TaggedDocument(words=[u'who', u'knew', u'make', u'movi', u'end', u'world', u'would', u'hard'], tags=['#1 at the Apocalypse Box Office (2015)'])]\n"
     ]
    }
   ],
   "source": [
    "print dftouse['plots'][2]\n",
    "print\n",
    "print documents_tm[2]\n",
    "print\n",
    "print documents_d2v[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(docs, name):\n",
    "    with open(dropbox + name + '.list', 'wb') as f:\n",
    "        for plot in docs:\n",
    "            f.write(\"%s\\n\" % plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the documents\n",
    "save(documents_tm, 'imdb_plots_since_2014.list')\n",
    "save(documents_d2v, 'imdb_plots_since_2014_d2v.list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the corresponding movies\n",
    "movies = dftouse['title'].values\n",
    "with open(dropbox +'imdb_movies_since_2014.pickle', 'wb') as f:\n",
    "    np.save(f,movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc = \"\"\"St. Johns, Newfoundland is a city with a deep musical spirit and few bands embody that spirit better that The Once. Named for a unique Newfoundland phrase that means \"imminently,\" now is indeed their time. Live at the Stagehouse is an hour of interviews and performances by this amazing trio, featuring songs recorded live off the floor in late 2013 at the picturesque Stagehouse Recording Studio in St. Philip's. The Once embraces a different vision of Newfoundland music. Their sounds do not come from the noisy pubs and dockside taverns that fuel so much of the Island's energy. Instead, their music comes from a quieter and more thoughtful place. Hope and tragedy are intertwined, whether they are singing an old lament from World War I, original songs that speak of love defeated, or tasteful songs from the artists whose music inspires them. The Once: Live at the Stagehouse features some of their best-loved tunes and some never heard before. It is a unique opportunity to see one of Canada's fastest rising bands in the place that inspires them and feeds their soul.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = process(sentences(doc))\n",
    "testpostags = process(sentences(doc),postags=['FW', 'JJ','JJR','JJS','NN','NNS','NNP', 'NNPS','VB','VBD','VBG','VBN','VBP','VBZ'])\n",
    "testkeywords = process(sentences(keywords(doc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([TaggedDocument(words=[u'st', u'john', u'newfoundland', u'is', u'citi', u'with', u'deep', u'music', u'spirit', u'and', u'few', u'band', u'embodi', u'that', u'spirit', u'better', u'that', u'the', u'onc'], tags=[None]), TaggedDocument(words=[u'name', u'for', u'uniqu', u'newfoundland', u'phrase', u'that', u'mean', u'immin', u'now', u'is', u'inde', u'their', u'time'], tags=[None]), TaggedDocument(words=[u'live', u'at', u'the', u'stagehous', u'is', u'an', u'hour', u'of', u'interview', u'and', u'perform', u'by', u'thi', u'amaz', u'trio', u'featur', u'song', u'record', u'live', u'off', u'the', u'floor', u'in', u'late', u'at', u'the', u'picturesqu', u'stagehous', u'record', u'studio', u'in', u'st', u'philip'], tags=[None]), TaggedDocument(words=[u'the', u'onc', u'embrac', u'differ', u'vision', u'of', u'newfoundland', u'music'], tags=[None]), TaggedDocument(words=[u'their', u'sound', u'do', u'not', u'come', u'from', u'the', u'noisi', u'pub', u'and', u'docksid', u'tavern', u'that', u'fuel', u'so', u'much', u'of', u'the', u'island', u'energi'], tags=[None]), TaggedDocument(words=[u'instead', u'their', u'music', u'come', u'from', u'quieter', u'and', u'more', u'thought', u'place'], tags=[None]), TaggedDocument(words=[u'hope', u'and', u'tragedi', u'are', u'intertwin', u'whether', u'they', u'are', u'sing', u'an', u'old', u'lament', u'from', u'world', u'war', u'origin', u'song', u'that', u'speak', u'of', u'love', u'defeat', u'or', u'tast', u'song', u'from', u'the', u'artist', u'whose', u'music', u'inspir', u'them'], tags=[None]), TaggedDocument(words=[u'the', u'onc', u'live', u'at', u'the', u'stagehous', u'featur', u'some', u'of', u'their', u'best-lov', u'tune', u'and', u'some', u'never', u'heard', u'befor'], tags=[None]), TaggedDocument(words=[u'it', u'is', u'uniqu', u'opportun', u'to', u'see', u'one', u'of', u'canada', u'fastest', u'rise', u'band', u'in', u'the', u'place', u'that', u'inspir', u'them', u'and', u'feed', u'their', u'soul'], tags=[None])], [u'st', u'john', u'newfoundland', u'is', u'citi', u'with', u'deep', u'music', u'spirit', u'and', u'few', u'band', u'embodi', u'that', u'spirit', u'better', u'that', u'the', u'onc', u'name', u'for', u'uniqu', u'newfoundland', u'phrase', u'that', u'mean', u'immin', u'now', u'is', u'inde', u'their', u'time', u'live', u'at', u'the', u'stagehous', u'is', u'an', u'hour', u'of', u'interview', u'and', u'perform', u'by', u'thi', u'amaz', u'trio', u'featur', u'song', u'record', u'live', u'off', u'the', u'floor', u'in', u'late', u'at', u'the', u'picturesqu', u'stagehous', u'record', u'studio', u'in', u'st', u'philip', u'the', u'onc', u'embrac', u'differ', u'vision', u'of', u'newfoundland', u'music', u'their', u'sound', u'do', u'not', u'come', u'from', u'the', u'noisi', u'pub', u'and', u'docksid', u'tavern', u'that', u'fuel', u'so', u'much', u'of', u'the', u'island', u'energi', u'instead', u'their', u'music', u'come', u'from', u'quieter', u'and', u'more', u'thought', u'place', u'hope', u'and', u'tragedi', u'are', u'intertwin', u'whether', u'they', u'are', u'sing', u'an', u'old', u'lament', u'from', u'world', u'war', u'origin', u'song', u'that', u'speak', u'of', u'love', u'defeat', u'or', u'tast', u'song', u'from', u'the', u'artist', u'whose', u'music', u'inspir', u'them', u'the', u'onc', u'live', u'at', u'the', u'stagehous', u'featur', u'some', u'of', u'their', u'best-lov', u'tune', u'and', u'some', u'never', u'heard', u'befor', u'it', u'is', u'uniqu', u'opportun', u'to', u'see', u'one', u'of', u'canada', u'fastest', u'rise', u'band', u'in', u'the', u'place', u'that', u'inspir', u'them', u'and', u'feed', u'their', u'soul'])\n",
      "\n",
      "([TaggedDocument(words=[u'picturesqu', u'stagehous', u'record', u'studio', u'featur', u'song', u'record', u'live', u'fastest', u'rise', u'band', u'deep', u'music', u'spirit', u'uniqu', u'newfoundland', u'phrase', u'tast', u'song', u'origin', u'song', u'uniqu', u'opportun', u'band', u'embodi', u'stagehous', u'featur', u'love', u'defeat', u'docksid', u'tavern', u'amaz', u'trio', u'best-lov', u'tune', u'world', u'war', u'noisi', u'pub', u'newfoundland', u'music', u'music', u'come', u'music', u'inspir', u'stagehous', u'live', u'spirit', u'newfoundland', u'inspir', u'name', u'inde', u'energi', u'john', u'embrac', u'heard', u'thought', u'artist', u'sound', u'sing', u'speak', u'canada', u'citi', u'quieter', u'floor', u'interview', u'mean', u'tragedi', u'fuel', u'instead', u'hope', u'island', u'philip', u'immin', u'intertwin', u'hour', u'lament', u'perform', u'soul', u'st', u'time', u'feed', u'vision', u'late'], tags=[None])], [u'picturesqu', u'stagehous', u'record', u'studio', u'featur', u'song', u'record', u'live', u'fastest', u'rise', u'band', u'deep', u'music', u'spirit', u'uniqu', u'newfoundland', u'phrase', u'tast', u'song', u'origin', u'song', u'uniqu', u'opportun', u'band', u'embodi', u'stagehous', u'featur', u'love', u'defeat', u'docksid', u'tavern', u'amaz', u'trio', u'best-lov', u'tune', u'world', u'war', u'noisi', u'pub', u'newfoundland', u'music', u'music', u'come', u'music', u'inspir', u'stagehous', u'live', u'spirit', u'newfoundland', u'inspir', u'name', u'inde', u'energi', u'john', u'embrac', u'heard', u'thought', u'artist', u'sound', u'sing', u'speak', u'canada', u'citi', u'quieter', u'floor', u'interview', u'mean', u'tragedi', u'fuel', u'instead', u'hope', u'island', u'philip', u'immin', u'intertwin', u'hour', u'lament', u'perform', u'soul', u'st', u'time', u'feed', u'vision', u'late'])\n",
      "\n",
      "([TaggedDocument(words=[u'st', u'john', u'newfoundland', u'is', u'citi', u'deep', u'music', u'spirit', u'few', u'band', u'embodi', u'spirit', u'onc'], tags=[None]), TaggedDocument(words=[u'name', u'uniqu', u'newfoundland', u'phrase', u'mean', u'is', u'time'], tags=[None]), TaggedDocument(words=[u'live', u'stagehous', u'is', u'hour', u'interview', u'perform', u'amaz', u'trio', u'featur', u'song', u'record', u'live', u'floor', u'late', u'picturesqu', u'stagehous', u'record', u'studio', u'st', u'philip'], tags=[None]), TaggedDocument(words=[u'onc', u'embrac', u'differ', u'vision', u'newfoundland', u'music'], tags=[None]), TaggedDocument(words=[u'sound', u'do', u'come', u'noisi', u'pub', u'docksid', u'tavern', u'fuel', u'island', u'energi'], tags=[None]), TaggedDocument(words=[u'music', u'come', u'quieter', u'thought', u'place'], tags=[None]), TaggedDocument(words=[u'hope', u'tragedi', u'are', u'intertwin', u'are', u'sing', u'old', u'lament', u'world', u'war', u'origin', u'song', u'speak', u'love', u'defeat', u'tast', u'song', u'artist', u'music', u'inspir'], tags=[None]), TaggedDocument(words=[u'onc', u'live', u'stagehous', u'featur', u'best-lov', u'tune', u'heard'], tags=[None]), TaggedDocument(words=[u'is', u'uniqu', u'opportun', u'see', u'canada', u'fastest', u'rise', u'band', u'place', u'inspir', u'feed', u'soul'], tags=[None])], [u'st', u'john', u'newfoundland', u'is', u'citi', u'deep', u'music', u'spirit', u'few', u'band', u'embodi', u'spirit', u'onc', u'name', u'uniqu', u'newfoundland', u'phrase', u'mean', u'is', u'time', u'live', u'stagehous', u'is', u'hour', u'interview', u'perform', u'amaz', u'trio', u'featur', u'song', u'record', u'live', u'floor', u'late', u'picturesqu', u'stagehous', u'record', u'studio', u'st', u'philip', u'onc', u'embrac', u'differ', u'vision', u'newfoundland', u'music', u'sound', u'do', u'come', u'noisi', u'pub', u'docksid', u'tavern', u'fuel', u'island', u'energi', u'music', u'come', u'quieter', u'thought', u'place', u'hope', u'tragedi', u'are', u'intertwin', u'are', u'sing', u'old', u'lament', u'world', u'war', u'origin', u'song', u'speak', u'love', u'defeat', u'tast', u'song', u'artist', u'music', u'inspir', u'onc', u'live', u'stagehous', u'featur', u'best-lov', u'tune', u'heard', u'is', u'uniqu', u'opportun', u'see', u'canada', u'fastest', u'rise', u'band', u'place', u'inspir', u'feed', u'soul'])\n"
     ]
    }
   ],
   "source": [
    "print test\n",
    "print\n",
    "print testkeywords\n",
    "print\n",
    "print testpostags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#process with spark\n",
    "'''import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "conf = (pyspark.SparkConf()\n",
    "    .setMaster('local')\n",
    "    .setAppName('pyspark')\n",
    "    .set(\"spark.executor.memory\", \"2g\"))\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "from pyspark.sql import SQLContext\n",
    "sqlsc=SQLContext(sc)\n",
    "plots_sdf = sqlsc.createDataFrame(dftouse)\n",
    "plots = (plots_sdf[['title','plots']]\n",
    "    .map(lambda x : (' '.join(x[1])))\n",
    ")\n",
    "docs = (plots\n",
    "    .map(sentences)\n",
    "    .map(process)          \n",
    ").cache()\n",
    "docs_sents = docs.map(lambda x : x[0]).collect()\n",
    "docs_words = docs.map(lambda x : x[1]).collect()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
