{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#pip install TextBlob\n",
    "#conda install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textblob as tb\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk.stem import *\n",
    "import urllib2\n",
    "from gensim import corpora, models, similarities\n",
    "import slugify as sl\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropbox = \"/Users/mr/Dropbox/moviemeta/\"\n",
    "movieplots = pd.read_csv(dropbox + 'movieplots.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean(row):\n",
    "    try:\n",
    "        row['year'] = int(row['year'])\n",
    "        return row\n",
    "    except:\n",
    "        row['year'] = np.nan\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this is because CSV conversion has converted list into string\n",
    "from ast import literal_eval\n",
    "movieplots['plots'] = movieplots['plots'].apply(literal_eval)\n",
    "\n",
    "movieplots = movieplots.apply(clean, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftouse = movieplots[movieplots.year > 2014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259028, 5)\n",
      "(16943, 5)\n"
     ]
    }
   ],
   "source": [
    "print movieplots.shape\n",
    "print dftouse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slugify (text):\n",
    "    return sl.slugify(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentences(text):\n",
    "    blob = tb.TextBlob(text.decode('unicode-escape', 'ignore'))\n",
    "    return blob.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    return PorterStemmer().stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num = re.compile('\\d')\n",
    "def contains_number(word):\n",
    "    return bool(num.search(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process(sents, dostop=True, dostem=True, donum=True, doslug=True):\n",
    "    stopwords = set(sw.words('english'))\n",
    "    sents_processed  = []\n",
    "    words_processed  = []\n",
    "    for sent in sents:\n",
    "        words = []\n",
    "        for word in sent.words:\n",
    "            if donum and contains_number(word):\n",
    "                    continue\n",
    "            if doslug:\n",
    "                word = slugify(word)\n",
    "            if dostop and word in stopwords:\n",
    "                    continue\n",
    "            if dostem:\n",
    "                word = stem(word)\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            words.append(word)\n",
    "        sents_processed.append(words)\n",
    "        words_processed += words \n",
    "    return (sents_processed, words_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "documents = dftouse['plots'].apply(lambda x : process(sentences(' '.join(x)))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save as pickle\n",
    "with open(dropbox +'imdb_plots_since_2014.pickle', 'wb') as f:\n",
    "    np.save(f, documents.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save as text file\n",
    "with open(dropbox +'imdb_plots_since_2014.list', 'wb') as f:\n",
    "    for plot in documents:\n",
    "        f.write(\"%s\\n\" % plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies = dftouse['title'].values\n",
    "with open(dropbox +'imdb_movies_since_2014.pickle', 'wb') as f:\n",
    "    np.save(f,movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#process with spark\n",
    "'''import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "conf = (pyspark.SparkConf()\n",
    "    .setMaster('local')\n",
    "    .setAppName('pyspark')\n",
    "    .set(\"spark.executor.memory\", \"2g\"))\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "from pyspark.sql import SQLContext\n",
    "sqlsc=SQLContext(sc)\n",
    "plots_sdf = sqlsc.createDataFrame(dftouse)\n",
    "plots = (plots_sdf[['title','plots']]\n",
    "    .map(lambda x : (' '.join(x[1])))\n",
    ")\n",
    "docs = (plots\n",
    "    .map(sentences)\n",
    "    .map(process)          \n",
    ").cache()\n",
    "docs_sents = docs.map(lambda x : x[0]).collect()\n",
    "docs_words = docs.map(lambda x : x[1]).collect()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
