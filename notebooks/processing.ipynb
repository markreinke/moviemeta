{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install TextBlob\n",
    "pip install python-rake\n",
    "conda install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textblob as tb\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk.stem import *\n",
    "import urllib2\n",
    "from gensim import models\n",
    "import slugify as sl\n",
    "import pickle\n",
    "import re\n",
    "import RAKE\n",
    "from ast import literal_eval\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, clean and filter our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropbox_dir = \"/Users/mr/Dropbox/moviemeta/\"\n",
    "#dropbox = urllib2.urlopen('https://www.dropbox.com/sh/bhrp12eqlj3zw0f/AAAlf4VJED2JXHLL6yUzuWoea?dl=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259028, 5)\n",
      "(26180, 12)\n"
     ]
    }
   ],
   "source": [
    "imdb_df = pd.read_csv(dropbox + 'movieplots.csv')\n",
    "wiki_df = pd.DataFrame()\n",
    "for year in range(2000, 2015):\n",
    "    df = pd.read_table(os.path.join(dropbox_dir, \"wikipedia\", \"wikipedia_plots_%d.csv\" % year))\n",
    "    wiki_df = pd.concat([wiki_df, df], ignore_index=True)\n",
    "print imdb_df.shape\n",
    "print wiki_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_imdb_df(row):\n",
    "    '''apply on rows of imdb dataframe to clean up'''\n",
    "    #concatanate multiple plots into one\n",
    "    row['plot'] = '\\n'.join(literal_eval(row['plots']))\n",
    "    try:\n",
    "        row['year'] = int(row['year'])\n",
    "        return row\n",
    "    except:\n",
    "        row['year'] = np.nan\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imdb_df = imdb_df.apply(clean_imdb_df, axis = 1)\n",
    "wiki_df.rename(columns = {'wiki_plot':'plot'}, inplace=True)\n",
    "imdb_df[['title','year']].to_csv(dropbox + 'imdb_meta_df.csv')\n",
    "wiki_df[['title','year', 'countries']].to_csv(dropbox + 'wiki_meta_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "      <th>year</th>\n",
       "      <th>plots</th>\n",
       "      <th>type</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#1 Cheerleader Camp (2010) (V)</td>\n",
       "      <td>imdb</td>\n",
       "      <td>2010</td>\n",
       "      <td>[\"When they're hired to work at a cheerleading...</td>\n",
       "      <td>user plot</td>\n",
       "      <td>When they're hired to work at a cheerleading c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#1 Serial Killer (2013)</td>\n",
       "      <td>imdb</td>\n",
       "      <td>2013</td>\n",
       "      <td>[\"Years of seething rage against the racism he...</td>\n",
       "      <td>user plot</td>\n",
       "      <td>Years of seething rage against the racism he's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#1 at the Apocalypse Box Office (2015)</td>\n",
       "      <td>imdb</td>\n",
       "      <td>2015</td>\n",
       "      <td>['Jules is, self declared, the most useless pe...</td>\n",
       "      <td>user plot</td>\n",
       "      <td>Jules is, self declared, the most useless pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#137 (2011)</td>\n",
       "      <td>imdb</td>\n",
       "      <td>2011</td>\n",
       "      <td>['#137 is a SCI/FI thriller about a girl, Marl...</td>\n",
       "      <td>user plot</td>\n",
       "      <td>#137 is a SCI/FI thriller about a girl, Marla,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#29 (2012)</td>\n",
       "      <td>imdb</td>\n",
       "      <td>2012</td>\n",
       "      <td>[\"In #29, the constant zooming into certain la...</td>\n",
       "      <td>user plot</td>\n",
       "      <td>In #29, the constant zooming into certain land...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title source  year  \\\n",
       "0          #1 Cheerleader Camp (2010) (V)   imdb  2010   \n",
       "1                 #1 Serial Killer (2013)   imdb  2013   \n",
       "2  #1 at the Apocalypse Box Office (2015)   imdb  2015   \n",
       "3                             #137 (2011)   imdb  2011   \n",
       "4                              #29 (2012)   imdb  2012   \n",
       "\n",
       "                                               plots       type  \\\n",
       "0  [\"When they're hired to work at a cheerleading...  user plot   \n",
       "1  [\"Years of seething rage against the racism he...  user plot   \n",
       "2  ['Jules is, self declared, the most useless pe...  user plot   \n",
       "3  ['#137 is a SCI/FI thriller about a girl, Marl...  user plot   \n",
       "4  [\"In #29, the constant zooming into certain la...  user plot   \n",
       "\n",
       "                                                plot  \n",
       "0  When they're hired to work at a cheerleading c...  \n",
       "1  Years of seething rage against the racism he's...  \n",
       "2  Jules is, self declared, the most useless pers...  \n",
       "3  #137 is a SCI/FI thriller about a girl, Marla,...  \n",
       "4  In #29, the constant zooming into certain land...  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>languages</th>\n",
       "      <th>countries</th>\n",
       "      <th>released</th>\n",
       "      <th>gross</th>\n",
       "      <th>comment</th>\n",
       "      <th>abstract</th>\n",
       "      <th>dbpediaLink</th>\n",
       "      <th>wikipediaLink</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>Well-Founded Fear</td>\n",
       "      <td>English</td>\n",
       "      <td>United States</td>\n",
       "      <td>As CNN Presents: Asylum in America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Well-Founded Fear is a 2000 documentary film f...</td>\n",
       "      <td>Well-Founded Fear is a 2000 documentary film f...</td>\n",
       "      <td>http://dbpedia.org/resource/Well-Founded_Fear</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Well-Founded_Fear</td>\n",
       "      <td>On average, only one in two hundred asylum app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>Thenali</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>India</td>\n",
       "      <td>2000-10-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thenali is a 2000 Indian Tamil comedy-drama fi...</td>\n",
       "      <td>Thenali is a 2000 Indian Tamil comedy-drama fi...</td>\n",
       "      <td>http://dbpedia.org/resource/Thenali</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Thenali</td>\n",
       "      <td>Thenali Soman (Kamal Hassan) is a man who fear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2000</td>\n",
       "      <td>The Season of Men</td>\n",
       "      <td>Arabic, French</td>\n",
       "      <td>France, Tunisia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Season of Men (Arabic: موسم الرجال (فيلم)‎...</td>\n",
       "      <td>The Season of Men (Arabic: موسم الرجال (فيلم)‎...</td>\n",
       "      <td>http://dbpedia.org/resource/The_Season_of_Men</td>\n",
       "      <td>http://en.wikipedia.org/wiki/The_Season_of_Men</td>\n",
       "      <td>An 18-year-old on the island Djerba, Aicha, is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2000</td>\n",
       "      <td>Beautiful Mistake</td>\n",
       "      <td>English</td>\n",
       "      <td>Wales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beautiful Mistake (Welsh: Camgymeriad Gwych) i...</td>\n",
       "      <td>Beautiful Mistake (Welsh: Camgymeriad Gwych) i...</td>\n",
       "      <td>http://dbpedia.org/resource/Beautiful_Mistake_...</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Beautiful_Mistake...</td>\n",
       "      <td>This documentary film follows a group of Welsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2000</td>\n",
       "      <td>Ready to Rumble</td>\n",
       "      <td>English</td>\n",
       "      <td>United States</td>\n",
       "      <td>Australia</td>\n",
       "      <td>12452362</td>\n",
       "      <td>Ready to Rumble is a 2000 American comedy film...</td>\n",
       "      <td>Ready to Rumble is a 2000 American comedy film...</td>\n",
       "      <td>http://dbpedia.org/resource/Ready_to_Rumble</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Ready_to_Rumble</td>\n",
       "      <td>For most of their lives, Sewage workers Gordie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  year              title       languages        countries  \\\n",
       "0           0  2000  Well-Founded Fear         English    United States   \n",
       "2           2  2000            Thenali           Tamil            India   \n",
       "6           6  2000  The Season of Men  Arabic, French  France, Tunisia   \n",
       "7           7  2000  Beautiful Mistake         English            Wales   \n",
       "8           8  2000    Ready to Rumble         English    United States   \n",
       "\n",
       "                             released     gross  \\\n",
       "0  As CNN Presents: Asylum in America       NaN   \n",
       "2                          2000-10-26       NaN   \n",
       "6                                 NaN       NaN   \n",
       "7                                 NaN       NaN   \n",
       "8                           Australia  12452362   \n",
       "\n",
       "                                             comment  \\\n",
       "0  Well-Founded Fear is a 2000 documentary film f...   \n",
       "2  Thenali is a 2000 Indian Tamil comedy-drama fi...   \n",
       "6  The Season of Men (Arabic: موسم الرجال (فيلم)‎...   \n",
       "7  Beautiful Mistake (Welsh: Camgymeriad Gwych) i...   \n",
       "8  Ready to Rumble is a 2000 American comedy film...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Well-Founded Fear is a 2000 documentary film f...   \n",
       "2  Thenali is a 2000 Indian Tamil comedy-drama fi...   \n",
       "6  The Season of Men (Arabic: موسم الرجال (فيلم)‎...   \n",
       "7  Beautiful Mistake (Welsh: Camgymeriad Gwych) i...   \n",
       "8  Ready to Rumble is a 2000 American comedy film...   \n",
       "\n",
       "                                         dbpediaLink  \\\n",
       "0      http://dbpedia.org/resource/Well-Founded_Fear   \n",
       "2                http://dbpedia.org/resource/Thenali   \n",
       "6      http://dbpedia.org/resource/The_Season_of_Men   \n",
       "7  http://dbpedia.org/resource/Beautiful_Mistake_...   \n",
       "8        http://dbpedia.org/resource/Ready_to_Rumble   \n",
       "\n",
       "                                       wikipediaLink  \\\n",
       "0     http://en.wikipedia.org/wiki/Well-Founded_Fear   \n",
       "2               http://en.wikipedia.org/wiki/Thenali   \n",
       "6     http://en.wikipedia.org/wiki/The_Season_of_Men   \n",
       "7  http://en.wikipedia.org/wiki/Beautiful_Mistake...   \n",
       "8       http://en.wikipedia.org/wiki/Ready_to_Rumble   \n",
       "\n",
       "                                                plot  \n",
       "0  On average, only one in two hundred asylum app...  \n",
       "2  Thenali Soman (Kamal Hassan) is a man who fear...  \n",
       "6  An 18-year-old on the island Djerba, Aicha, is...  \n",
       "7  This documentary film follows a group of Welsh...  \n",
       "8  For most of their lives, Sewage workers Gordie...  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the movie plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define some functions that we are going to use to process the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slugify (text):\n",
    "    \"\"\"replace special characters with ascii, see https://github.com/un33k/python-slugify\"\"\"\n",
    "    return sl.slugify(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    \"\"\"stem a word with Porter Stemmer\"\"\"\n",
    "    return PorterStemmer().stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num = re.compile('\\d')\n",
    "def contains_number(word):\n",
    "    \"\"\"check if a word contains a number\"\"\"\n",
    "    return bool(num.search(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Rake = RAKE.Rake('/Users/mr/Devel/Harvard/CS109/Project/moviemeta/data/stoplists/FoxStoplist.txt')\n",
    "def keywords(text):\n",
    "    \"\"\"extract keywords from text using RAKE algorithm\"\"\"\n",
    "    keywords = Rake.run(text)\n",
    "    return ' '.join([tup[0] for tup in keywords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentences(text):\n",
    "    \"\"\" tokenize text into sentences using nltk's punkt tokenizer\"\"\"\n",
    "    blob = tb.TextBlob(text.decode('unicode-escape', 'ignore'))\n",
    "    return blob.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process(sents, movie_id=None, stop=False, postags=None ):\n",
    "    \"\"\"process a list of sentences\n",
    "    \n",
    "    Apply stemming, removal of numbers, slugifying to text\n",
    "    Optionally remove stop words, only include words with a certain POS tag\n",
    "    \n",
    "    Args:\n",
    "        sents (list): sentences\n",
    "        movie_id (int): movie id of the document that is processed\n",
    "        stop (bool): remove stopwords\n",
    "        postags(list): list of POS tags\n",
    "    Returns:\n",
    "        tuple containing two represantions of a daocument:\n",
    "        A list of tagged sentences (e.g. for doc2vec) and a list of words (e.g. for topic detection)\n",
    "    \"\"\"\n",
    "    if stop:\n",
    "        stopwords = set(sw.words('english'))\n",
    "    doc_sents  = []\n",
    "    doc_words  = []\n",
    "    for sent in sents:\n",
    "        if postags:\n",
    "            words = sent.tags\n",
    "        else:\n",
    "            words = sent.words\n",
    "        words_processed = []\n",
    "        for word in words:\n",
    "            if postags:\n",
    "                if word[1] not in postags:\n",
    "                    continue\n",
    "                else:\n",
    "                    word = word[0]\n",
    "            if stop and word in stopwords:\n",
    "                    continue\n",
    "            if contains_number(word):\n",
    "                    continue\n",
    "            word = stem(slugify(word))\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            words_processed.append(word)\n",
    "        doc_sents.append(models.doc2vec.LabeledSentence(words_processed,[movie_id]))\n",
    "        doc_words += words_processed \n",
    "    return (doc_sents, doc_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the actual processing. For topic detection we apply keyword extraction, as we want to use only use those words that carry meaning. We then apply normalization and transform the plots into lists of words, that will later be transformed into bags of words for topic detection.\n",
    "For doc2vec we return lists of tagged sentences, as this is the input for a doc2vec training corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_tm(row):\n",
    "    \"\"\"process a row of a dataframe for topic modeling\"\"\"\n",
    "    return process(sentences(keywords((row))))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb_plots_tm = imdb_df['plot'].apply(process_tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wiki_df = wiki_df[~ wiki_df['plot'].isnull()]\n",
    "wiki_plots_tm = wiki_df['plot'].apply(process_tm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_d2v(row):\n",
    "    title = row[0]\n",
    "    plot = row[1]\n",
    "    return  process(sentences(plot), movie_id=title, stop=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3) into shape (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-d47daac461e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimdb_plots_d2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimdb_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'plot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_d2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/mr/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   3716\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3717\u001b[0m         \u001b[0mlevel\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthese\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3718\u001b[0;31m             \u001b[0mLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mto\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcan\u001b[0m \u001b[0;32mpass\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3719\u001b[0m         \u001b[0mdropna\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mboolean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3720\u001b[0m             \u001b[0mWhether\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdrop\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresulting\u001b[0m \u001b[0mFrame\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSeries\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mno\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mr/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   3823\u001b[0m         \u001b[0mbm_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3824\u001b[0m         \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mperiods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3825\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[0;31m#----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mr/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     def __init__(self, data=None, index=None, columns=None, dtype=None,\n\u001b[0;32m--> 214\u001b[0;31m                  copy=False):\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mr/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                         \u001b[0;31m# 1783\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m                         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflexible\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mr/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   4806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4807\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4808\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4809\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4810\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mr/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[0;34m(arrays, names, axes)\u001b[0m\n\u001b[1;32m   3558\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3560\u001b[0;31m         \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mr/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   3523\u001b[0m         l, r = items_overlap_with_suffix(left=self.items, lsuffix=lsuffix,\n\u001b[1;32m   3524\u001b[0m                                          right=other.items, rsuffix=rsuffix)\n\u001b[0;32m-> 3525\u001b[0;31m         \u001b[0mnew_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concat_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m         new_blocks = [blk.copy(deep=False)\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (3) into shape (2)"
     ]
    }
   ],
   "source": [
    "imdb_plots_d2v = imdb_df[['title','plot']].apply(process_d2v, axis=1)\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_plots_d2v = wiki_df[['title','plot']].apply(process_d2v, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jules is, self declared, the most useless person in the post apocalyptic world, until he finds an old film camera and determines to make the greatest movie in the new world... the only movie in the new world. But his first day filming is proving to be much more difficult than he imagined. Who knew that making a movie after the end of the world would be so hard?']\n",
      "\n",
      "[u'post', u'apocalypt', u'world', u'day', u'film', u'film', u'camera', u'useless', u'person', u'self', u'declar', u'world', u'determin', u'movi', u'prove', u'jule', u'imagin', u'hard', u'difficult']\n",
      "\n",
      "[TaggedDocument(words=[u'jule', u'self', u'declar', u'useless', u'person', u'post', u'apocalypt', u'world', u'find', u'old', u'film', u'camera', u'determin', u'make', u'greatest', u'movi', u'new', u'world', u'movi', u'new', u'world'], tags=['#1 at the Apocalypse Box Office (2015)']), TaggedDocument(words=[u'but', u'first', u'day', u'film', u'prove', u'much', u'difficult', u'imagin'], tags=['#1 at the Apocalypse Box Office (2015)']), TaggedDocument(words=[u'who', u'knew', u'make', u'movi', u'end', u'world', u'would', u'hard'], tags=['#1 at the Apocalypse Box Office (2015)'])]\n"
     ]
    }
   ],
   "source": [
    "print dftouse['plots'][2]\n",
    "print\n",
    "print documents_tm[2]\n",
    "print\n",
    "print documents_d2v[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(docs, name):\n",
    "    with open(dropbox + name + '.list', 'wb') as f:\n",
    "        for plot in docs:\n",
    "            f.write(\"%s\\n\" % plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the documents\n",
    "#save(imdb_plots_tm , 'imdb_plots')\n",
    "#save(wiki_plots_tm , 'wiki_plots_2000-2015')\n",
    "with open(dropbox +'imdb_plots_d2v.pickle', 'wb') as f:\n",
    "    np.save(f, documents_d2v.values)\n",
    "with open(dropbox +'wiki_plots_d2v.pickle', 'wb') as f:\n",
    "    np.save(f, documents_d2v.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the corresponding movies\n",
    "movies = dftouse['title'].values\n",
    "with open(dropbox +'imdb_movies_since_2014.pickle', 'wb') as f:\n",
    "    np.save(f,movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc = \"\"\"St. Johns, Newfoundland is a city with a deep musical spirit and few bands embody that spirit better that The Once. Named for a unique Newfoundland phrase that means \"imminently,\" now is indeed their time. Live at the Stagehouse is an hour of interviews and performances by this amazing trio, featuring songs recorded live off the floor in late 2013 at the picturesque Stagehouse Recording Studio in St. Philip's. The Once embraces a different vision of Newfoundland music. Their sounds do not come from the noisy pubs and dockside taverns that fuel so much of the Island's energy. Instead, their music comes from a quieter and more thoughtful place. Hope and tragedy are intertwined, whether they are singing an old lament from World War I, original songs that speak of love defeated, or tasteful songs from the artists whose music inspires them. The Once: Live at the Stagehouse features some of their best-loved tunes and some never heard before. It is a unique opportunity to see one of Canada's fastest rising bands in the place that inspires them and feeds their soul.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = process(sentences(doc))\n",
    "testpostags = process(sentences(doc),postags=['FW', 'JJ','JJR','JJS','NN','NNS','NNP', 'NNPS','VB','VBD','VBG','VBN','VBP','VBZ'])\n",
    "testkeywords = process(sentences(keywords(doc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'st', u'john', u'newfoundland', u'is', u'citi', u'with', u'deep', u'music', u'spirit', u'and', u'few', u'band', u'embodi', u'that', u'spirit', u'better', u'that', u'the', u'onc', u'name', u'for', u'uniqu', u'newfoundland', u'phrase', u'that', u'mean', u'immin', u'now', u'is', u'inde', u'their', u'time', u'live', u'at', u'the', u'stagehous', u'is', u'an', u'hour', u'of', u'interview', u'and', u'perform', u'by', u'thi', u'amaz', u'trio', u'featur', u'song', u'record', u'live', u'off', u'the', u'floor', u'in', u'late', u'at', u'the', u'picturesqu', u'stagehous', u'record', u'studio', u'in', u'st', u'philip', u'the', u'onc', u'embrac', u'differ', u'vision', u'of', u'newfoundland', u'music', u'their', u'sound', u'do', u'not', u'come', u'from', u'the', u'noisi', u'pub', u'and', u'docksid', u'tavern', u'that', u'fuel', u'so', u'much', u'of', u'the', u'island', u'energi', u'instead', u'their', u'music', u'come', u'from', u'quieter', u'and', u'more', u'thought', u'place', u'hope', u'and', u'tragedi', u'are', u'intertwin', u'whether', u'they', u'are', u'sing', u'an', u'old', u'lament', u'from', u'world', u'war', u'origin', u'song', u'that', u'speak', u'of', u'love', u'defeat', u'or', u'tast', u'song', u'from', u'the', u'artist', u'whose', u'music', u'inspir', u'them', u'the', u'onc', u'live', u'at', u'the', u'stagehous', u'featur', u'some', u'of', u'their', u'best-lov', u'tune', u'and', u'some', u'never', u'heard', u'befor', u'it', u'is', u'uniqu', u'opportun', u'to', u'see', u'one', u'of', u'canada', u'fastest', u'rise', u'band', u'in', u'the', u'place', u'that', u'inspir', u'them', u'and', u'feed', u'their', u'soul']\n",
      "\n",
      "[u'picturesqu', u'stagehous', u'record', u'studio', u'featur', u'song', u'record', u'live', u'fastest', u'rise', u'band', u'deep', u'music', u'spirit', u'uniqu', u'newfoundland', u'phrase', u'tast', u'song', u'origin', u'song', u'uniqu', u'opportun', u'band', u'embodi', u'stagehous', u'featur', u'love', u'defeat', u'docksid', u'tavern', u'amaz', u'trio', u'best-lov', u'tune', u'world', u'war', u'noisi', u'pub', u'newfoundland', u'music', u'music', u'come', u'music', u'inspir', u'stagehous', u'live', u'spirit', u'newfoundland', u'inspir', u'name', u'inde', u'energi', u'john', u'embrac', u'heard', u'thought', u'artist', u'sound', u'sing', u'speak', u'canada', u'citi', u'quieter', u'floor', u'interview', u'mean', u'tragedi', u'fuel', u'instead', u'hope', u'island', u'philip', u'immin', u'intertwin', u'hour', u'lament', u'perform', u'soul', u'st', u'time', u'feed', u'vision', u'late']\n",
      "\n",
      "[u'st', u'john', u'newfoundland', u'is', u'citi', u'deep', u'music', u'spirit', u'few', u'band', u'embodi', u'spirit', u'onc', u'name', u'uniqu', u'newfoundland', u'phrase', u'mean', u'is', u'time', u'live', u'stagehous', u'is', u'hour', u'interview', u'perform', u'amaz', u'trio', u'featur', u'song', u'record', u'live', u'floor', u'late', u'picturesqu', u'stagehous', u'record', u'studio', u'st', u'philip', u'onc', u'embrac', u'differ', u'vision', u'newfoundland', u'music', u'sound', u'do', u'come', u'noisi', u'pub', u'docksid', u'tavern', u'fuel', u'island', u'energi', u'music', u'come', u'quieter', u'thought', u'place', u'hope', u'tragedi', u'are', u'intertwin', u'are', u'sing', u'old', u'lament', u'world', u'war', u'origin', u'song', u'speak', u'love', u'defeat', u'tast', u'song', u'artist', u'music', u'inspir', u'onc', u'live', u'stagehous', u'featur', u'best-lov', u'tune', u'heard', u'is', u'uniqu', u'opportun', u'see', u'canada', u'fastest', u'rise', u'band', u'place', u'inspir', u'feed', u'soul']\n"
     ]
    }
   ],
   "source": [
    "print test[1]\n",
    "print\n",
    "print testkeywords[1]\n",
    "print\n",
    "print testpostags[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
